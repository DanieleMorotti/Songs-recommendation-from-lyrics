{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "p_TeX6iguEBh",
        "MW7lD6DpldqT"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Songs recommendation with GNN"
      ],
      "metadata": {
        "id": "xLECgWNJuDPp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graph Neural Networks (GNNs) have recently gained increasing popularity in both research and real-world applications, therefore I decided to test several models in order to learn from the lyrics and from some other features of the songs, which are the ones related to each other.\n"
      ],
      "metadata": {
        "id": "0WOzl34d0f8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "i4JzVd1zZW3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installation of the libraries and download of the datasets"
      ],
      "metadata": {
        "id": "z4WK5k7N0aab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As dataset I used a subset of the [Million Songs Dataset](http://millionsongdataset.com/), created by combining the musiXmatch and the Last.fm versions to retrieve the song lyrics and the similar songs respectively. You can download the script that create the dataset from Drive and execute it to create also the datasets for the analysis on R.\n",
        "\n",
        "For the creation of the models I used the [PyTorch Geometric](https://pytorch-geometric.readthedocs.io/en/latest/) library, because is probably the most efficient and well supported tool for dealing with GNNs."
      ],
      "metadata": {
        "id": "L55SMK6WZty7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(f\"torch version: {torch.__version__}\")\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-geometric -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "\n",
        "!pip install --upgrade --no-cache-dir -q gdown\n",
        "import gdown"
      ],
      "metadata": {
        "id": "c6WCiStzNd7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e4a1ed-663d-457e-f5c2-7b239dd43f0e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 1.13.1+cu116\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells you can choose between downloading and creating the dataset elaborating the data from the [Million Song Dataset](http://millionsongdataset.com/) (also using the musiXmatch and the Last.fm versions) or to copy the already created files from Drive."
      ],
      "metadata": {
        "id": "9L7GseIgpt9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### Download script and create the datasets\n",
        "#@markdown It first downloads the script and then it executes it to create the needed datasets.\n",
        "#url_script = \"\"\n",
        "#gdown.download(id=url_script, output=\"create_dataset.py\", quiet=True)\n",
        "\n",
        "!python create_dataset.py"
      ],
      "metadata": {
        "cellView": "form",
        "id": "5Tb0GhggjyyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### Load the files from Drive\n",
        "#@markdown Download the training and evaluation dataset from Drive.\n",
        "\n",
        "# File ids in Drive\n",
        "url_train_data = \"1-1I90HW0wZ1eVgXX9KETgEgYcnvJ0qAg\"\n",
        "url_validation_data = \"1-1kUEXn2Hw_FB-xWbXk6njIao2RwhSSO\"\n",
        "\n",
        "gdown.download(id=url_train_data, output=\"songs_train.csv\", quiet=False)\n",
        "gdown.download(id=url_validation_data, output=\"songs_val.csv\", quiet=False)"
      ],
      "metadata": {
        "id": "yQDiL4g_guxc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The downloaded files are not suitable to work with PyG, therefore I made some preprocessing on the dataframe in order to create the nodes and the edges of the GNN."
      ],
      "metadata": {
        "id": "NXk7HrgKxxB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing to create graph data"
      ],
      "metadata": {
        "id": "014OtjHQ9NiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As said before, the downloaded dataframe is not usable for creating the GNN, I have to preprocess the data in a specific way, creating the ids for the nodes, generating the edges and computing the features to use for these elements. First of all let's import all the needed libraries."
      ],
      "metadata": {
        "id": "BC6fxehjcgl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the PyG modules\n",
        "from torch_geometric import seed_everything\n",
        "from torch_geometric.data import Data, Dataset, InMemoryDataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.transforms import RandomLinkSplit\n",
        "from torch_geometric.utils import degree\n",
        "\n",
        "# Basic modules to deal with dataframe\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Scikit-learn modules to create song lyrics embeddings\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, Normalizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Monitor the progress of the functions\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "# nltk preprocessing to remove stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords', quiet=True)\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Set a seed for every random operation\n",
        "seed_everything(88)"
      ],
      "metadata": {
        "id": "RY0LAOGcGZXM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the preprocessed files"
      ],
      "metadata": {
        "id": "TDjXlj3vydAe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the files from Drive avoiding to run the preprocessing operations and load them into some variables."
      ],
      "metadata": {
        "id": "llSRMLHwyidb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_graph_data = \"1WKrN3NpXNdIovXdwEeGH9ZEUUYNOVI6j\"\n",
        "url_core_mapping = \"1-3K1BqkUItn93_m7Wq1QGvESAXrt0RCd\"\n",
        "url_track_id_mapping = \"1-548e0dADOLkbRoirJVTw5I2_ni1Ldif\"\n",
        "url_reduced_df = \"1-1PXzF3XK6TsFdfvaxM708nCUrZKkRPz\"\n",
        "\n",
        "file_names = ['graph_data.pt', 'core_mapping.json', 'track_id_mapping.json', 'reduced_df.csv']\n",
        "\n",
        "for name, url_id in zip(file_names, [url_graph_data, url_core_mapping, url_track_id_mapping, url_reduced_df]):\n",
        "    gdown.download(id=url_id, output=name, quiet=True)"
      ],
      "metadata": {
        "id": "siBg_97WuGd7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After having loaded the pre-saved files from Drive, execute the following cell to have the data loaded in the variables."
      ],
      "metadata": {
        "id": "iPQNMi5PwLfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_df = pd.read_csv(file_names[3])\n",
        "\n",
        "with open(file_names[1], 'r') as fin1, open(file_names[2], 'r') as fin2:\n",
        "    core_mapping = json.load(fin1)\n",
        "    id_mapping = json.load(fin2)\n",
        "\n",
        "graph_data = torch.load(file_names[0])\n",
        "\n",
        "track_to_id, id_to_track = id_mapping['track_to_id'], id_mapping['id_to_track']\n",
        "old_to_core_id, core_to_old_id = core_mapping['old_to_core_id'], core_mapping['core_to_old_id']"
      ],
      "metadata": {
        "id": "dUBNt7UawSnD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point you can skip the preprocessing part and go to the training section."
      ],
      "metadata": {
        "id": "MDRpSmbXx-6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute preprocessing"
      ],
      "metadata": {
        "id": "p_TeX6iguEBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following cells there are all the needed passages to build the files that I also saved to Drive."
      ],
      "metadata": {
        "id": "xucZYqw8wY7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### Preprocessing useful functions\n",
        "#@markdown In this cell I implemented different functions to make the preprocessing operations.\n",
        "def check_evaluation_dataset(target, track_id_list):\n",
        "    '''\n",
        "        It removes from the target string all the similar songs that are not\n",
        "        in our main dataset.\n",
        "    '''\n",
        "    target_list = target.split(',')\n",
        "    # We need to preserve the order of relevance for computing the mAP\n",
        "    present = sorted(set(target_list).intersection(track_id_list), key=target_list.index)\n",
        "    return ','.join(present)\n",
        "\n",
        "\n",
        "def remove_stopwords(text, stop):\n",
        "    '''\n",
        "        It returns the string without the words within the list 'stop'.\n",
        "    '''\n",
        "    result = ' '.join([word for word in text.split(\" \") if word not in stop])\n",
        "    return result\n",
        "\n",
        "\n",
        "def compute_LSA(corpus, max_features_tfidf=2000, k_svd=200):\n",
        "    '''\n",
        "        It returns the documents matrix multiplied by the singular values, both\n",
        "        computed using SVD truncated at k_svd.\n",
        "\n",
        "        Parameters:\n",
        "            - corpus: pd.Series\n",
        "                The pandas series where the function will find the texts you want\n",
        "                to use for the creation of the matrix.\n",
        "            - max_features: int\n",
        "                The maximum number of features to use for the TF-IDF matrix.\n",
        "            - k_svd: int\n",
        "                The number at which truncate the SVD matrix.\n",
        "            \n",
        "        Returns:\n",
        "            - dict, torch.tensor\n",
        "                It returns the dictionary used in the TF-IDF matrix, the tensor\n",
        "                U * sigma of the SVD decomposition, i.e. the documents matrix, and\n",
        "                the transpose of the terms matrix.\n",
        "    '''\n",
        "    # The number of terms to keep, almost half in this case\n",
        "    tfidf_vectorizer = TfidfVectorizer(max_features=max_features_tfidf)\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "    # Standardizing the vectors\n",
        "    #tfidf_matrix = StandardScaler().fit_transform(tfidf_matrix.toarray())\n",
        "    \n",
        "    # Specify the number of latent dimensions\n",
        "    lsa = TruncatedSVD(n_components=k_svd)\n",
        "    \n",
        "    # Apply the truncatedSVD function, the fit_transform function returns U*sigma\n",
        "    documents_lsa = lsa.fit_transform(tfidf_matrix) \n",
        "    # Shape of the reduced matrix\n",
        "    print(f\"The documents matrix after the SVD decomposition has shape {documents_lsa.shape}\")\n",
        "\n",
        "    # Normalize the vectors\n",
        "    documents_lsa = Normalizer(copy=False).fit_transform(documents_lsa)\n",
        "\n",
        "    return tfidf_vectorizer.vocabulary_, torch.tensor(documents_lsa, dtype=torch.float32), torch.tensor(lsa.components_, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def project_text_lsa(text, vocabulary, words_matrix):\n",
        "    '''\n",
        "        It projects a given text in the latent space, it first computes the TF-IDF\n",
        "        vector considering the same vocabulary used to build the latent space and \n",
        "        then it projects the vector using the transpose words matrix. \n",
        "    '''\n",
        "    vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
        "\n",
        "    tf_idf_vector = torch.tensor(vectorizer.fit_transform([text]).toarray(), dtype=torch.float32)\n",
        "\n",
        "    # Compute the projection\n",
        "    ls_vector = tf_idf_vector @ words_matrix.t()\n",
        "\n",
        "    return ls_vector\n",
        "\n",
        "\n",
        "def map_string_ids_to_num(str_list, mapping):\n",
        "    conversion = str_list\n",
        "    for tid in str_list.split(\",\"):\n",
        "        if tid in mapping:\n",
        "            conversion = conversion.replace(tid, str(mapping[tid]))\n",
        "        else:\n",
        "            # Remove ids that are not in the dataset\n",
        "            conversion = conversion.replace(f'{tid},', '')\n",
        "    return conversion"
      ],
      "metadata": {
        "id": "Wp4Ilv3JsTVw",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The needed operations, before to create the graph, are the following:\n",
        "- remove the NA elements from the dataframe;\n",
        "- keep only the nodes with a number of similar songs between 5 and 50 in order to reduce the dataset;\n",
        "- remove the stopwords from the lyrics;\n",
        "- check that in the similar song lists there are songs still present in the dataset."
      ],
      "metadata": {
        "id": "jPoNlYeZdUp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv('songs_train.csv')\n",
        "print(f\"The length of the dataframe is {len(train_df)}.\\n\")\n",
        "\n",
        "train_df = train_df.dropna()\n",
        "# Keep only the nodes that have between 5 and 50 similar songs (edges)\n",
        "reduced_df = train_df[(train_df['similars'].str.split(',').apply(len) >= 5) & (train_df['similars'].str.split(',').apply(len) <= 50)]\n",
        "\n",
        "# Remove the stopwords from the lyrics\n",
        "tqdm.pandas(desc=\"- Removing stopwords from lyrics\")\n",
        "reduced_df['lyrics'] = reduced_df['lyrics'].progress_apply(remove_stopwords, stop=stop)\n",
        "\n",
        "# Check and keep only the lyrics with at least one word\n",
        "reduced_df = reduced_df[~(reduced_df['lyrics'] == \"\")]\n",
        "tqdm.pandas(desc=\"- (1) Keep only similar songs that are in the dataset\")\n",
        "reduced_df['similars'] = reduced_df['similars'].progress_apply(check_evaluation_dataset, track_id_list=reduced_df['track_id'].tolist())\n",
        "\n",
        "# Remove the songs that are without similars\n",
        "reduced_df = reduced_df[~(reduced_df.similars == \"\")].reset_index(drop=True)\n",
        "# Last check after removal of songs without similars\n",
        "tqdm.pandas(desc=\"- (2) Keep only similar songs that are in the dataset\")\n",
        "reduced_df['similars'] = reduced_df['similars'].progress_apply(check_evaluation_dataset, track_id_list=reduced_df['track_id'].tolist())\n",
        "\n",
        "print(f\"\\n\\nThe length of the reduced dataframe is {len(reduced_df)}.\")"
      ],
      "metadata": {
        "id": "OGW-1rjmd5eQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b9da346-99ae-40e9-c8c0-ef862132ae02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The length of the dataframe is 105031.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "- Removing stopwords from lyrics: 100%|██████████| 75661/75661 [00:29<00:00, 2582.90it/s]\n",
            "- (1) Keep only similar songs that are in the dataset: 100%|██████████| 75654/75654 [05:32<00:00, 227.47it/s]\n",
            "- (2) Keep only similar songs that are in the dataset: 100%|██████████| 75645/75645 [05:50<00:00, 216.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The length of the reduced dataframe is 75645.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the previous steps I create a numerical id for the songs and for the tags (genres)."
      ],
      "metadata": {
        "id": "6MJdKtBpfrw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode each song with a numerical ID\n",
        "item_encoder = LabelEncoder()\n",
        "reduced_df['item_id'] = item_encoder.fit_transform(reduced_df['track_id'])\n",
        "\n",
        "# Encode the genre as numerical values\n",
        "genre_encoder = LabelEncoder()\n",
        "reduced_df['tag'] = genre_encoder.fit_transform(reduced_df['tag'])"
      ],
      "metadata": {
        "id": "G0faT0LNEawL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I also created a mapping to convert from string ids to numerical ones and viceversa, then I apply the conversion to the similar song lists."
      ],
      "metadata": {
        "id": "eEUYtRlCgDBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the mapping from track_id to item_id and viceversa\n",
        "track_to_id = {}\n",
        "id_to_track = {}\n",
        "for tid, iid in zip(reduced_df['track_id'], reduced_df['item_id']):\n",
        "    track_to_id[tid] = iid\n",
        "    id_to_track[iid] = tid\n",
        "\n",
        "# Convert the list of similar songs to list of numerical ids\n",
        "tqdm.pandas(desc=\"Convert similar songs track ids to numerical ids\")\n",
        "reduced_df['similars'] = reduced_df['similars'].progress_apply(map_string_ids_to_num, mapping=track_to_id)"
      ],
      "metadata": {
        "id": "XovUyWPwEgSg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After all this operations I can create the graph structure that I will use later for the GNN model."
      ],
      "metadata": {
        "id": "pVOlScTYzoBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Creation of the nodes and edges data"
      ],
      "metadata": {
        "id": "1GbyDczFhHWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q snap-stanford\n",
        "\n",
        "# Install snap for simple graph creation\n",
        "import snap"
      ],
      "metadata": {
        "id": "6znHH7auh6Yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e1bd5c-7593-4d58-dfc1-0d6d48313371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "G = snap.snap.TUNGraph().New()\n",
        "\n",
        "# First add all song IDs as nodes in G\n",
        "for i in tqdm(range(len(reduced_df))):\n",
        "    song = int(reduced_df.loc[i, 'item_id'])\n",
        "    if not G.IsNode(song):\n",
        "        G.AddNode(song)\n",
        "    # Add a node for each similar song and then add the edge\n",
        "    for sim in reduced_df.loc[i, 'similars'].split(\",\"):\n",
        "        if not G.IsNode(int(sim)):\n",
        "            G.AddNode(int(sim))\n",
        "        G.AddEdge(song, int(sim))\n",
        "\n",
        "print(\"Original graph:\")\n",
        "print(f\"Num nodes: {len([x for x in G.Nodes()])} ({len(reduced_df['item_id'])} unique songs)\")\n",
        "print(f\"Num edges: {len([x for x in G.Edges()])} (undirected)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV-shwPGhxeY",
        "outputId": "5f71b07e-f833-47b1-a8b9-7a106b9cd45f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 75645/75645 [00:04<00:00, 15317.53it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: add explanation about core graph "
      ],
      "metadata": {
        "id": "-VwL27H10APq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 30\n",
        "kcore = G.GetKCore(K)\n",
        "if kcore.Empty():\n",
        "    raise Exception(f\"No Core exists for K={K}\")\n",
        "\n",
        "print(\"K-core graph:\")\n",
        "print(f\"Num nodes: {len([x for x in kcore.Nodes()])} (and unique songs)\")\n",
        "print(f\"Num edges: {len([x for x in kcore.Edges()])} (undirected)\")"
      ],
      "metadata": {
        "id": "KPvOSNEpA8b3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I need to re-index the nodes from 0 to n to avoid problem with PyG and I save the mapping such that I will be able to convert the new ids to the original ones."
      ],
      "metadata": {
        "id": "3gbZ__Xp0P9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to re-index the nodes, otherwise some problems later with PyG\n",
        "old_to_core_id = {}\n",
        "core_to_old_id = {}\n",
        "for i, NI in enumerate(kcore.Nodes()):\n",
        "    old_id = NI.GetId()\n",
        "    assert old_id not in old_to_core_id\n",
        "    new_id = i\n",
        "    old_to_core_id[old_id] = new_id\n",
        "    core_to_old_id[new_id] = old_id "
      ],
      "metadata": {
        "id": "8fXZaHwJBtsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I can convert the given graph structure to the one compatible with PyG and I create a Data object."
      ],
      "metadata": {
        "id": "i0FmOcQT0pNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert snap graph to a format that can be used in PyG, converting to edge_index and storing in a PyG Data object\n",
        "all_edges = []\n",
        "for EI in tqdm(kcore.Edges()):\n",
        "    edge_info = [old_to_core_id[EI.GetSrcNId()], old_to_core_id[EI.GetDstNId()]]\n",
        "    all_edges.append(edge_info)\n",
        "    # Also add the edge in the opposite direction because undirected\n",
        "    all_edges.append(edge_info[::-1]) \n",
        "edge_idx = torch.LongTensor(all_edges)\n",
        "\n",
        "graph_data = Data(edge_index=edge_idx.t().contiguous(), num_nodes=kcore.GetNodes())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1t987e5S8Wl",
        "outputId": "bfd0dfe9-81f0-4a48-f360-2bf4f41655bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "176020it [00:01, 112467.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use these data in a future run I save reduced_df, graph_data and the mappings in some files that I put on Drive. "
      ],
      "metadata": {
        "id": "Sk-aofr002Xd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Data object (for training model) and the reduced df for retrieving info about the songs in the future\n",
        "torch.save(graph_data, 'graph_data.pt')\n",
        "# Save the reduced df and the mapping from one index to another\n",
        "reduced_df.to_csv('reduced_df_GNN.csv', index=False)\n",
        "core_mapping = {'old_to_core_id': old_to_core_id, 'core_to_old_id': core_to_old_id}\n",
        "id_mapping = {'track_to_id': track_to_id, 'id_to_track': id_to_track}\n",
        "\n",
        "with open('core_mapping.json', 'w') as fp1, open('track_id_mapping.json', 'w') as fp2:\n",
        "    json.dump(core_mapping, fp1)\n",
        "    json.dump(id_mapping, fp2)"
      ],
      "metadata": {
        "id": "sp3FCMkYTeKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create graph features to use in the GNN "
      ],
      "metadata": {
        "id": "Ks4S8f1PzTQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "songs_vocabulary, songs_lsa, terms_lsa = compute_LSA(reduced_df['lyrics'], max_features_tfidf=2000, k_svd=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyiGaOV9zbyo",
        "outputId": "e4f99c3d-9307-41cd-a4c3-a1ce80febf8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The documents matrix after the SVD decomposition has shape (75645, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as T\n",
        "\n",
        "class MSongsDataset(InMemoryDataset):\n",
        "    def __init__(self, root, transform=None, pre_transform=None):\n",
        "        super(MSongsDataset, self).__init__(root, transform, pre_transform)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return 'graph_data.pt'\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'processed_data.pt'\n",
        "\n",
        "    def download(self):\n",
        "        # Download to `self.raw_dir`.\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "\n",
        "        core_ids = [core_to_old_id[str(node.item())] for node in torch.unique(graph_data.edge_index[0,:])]\n",
        "        core_songs = songs_lsa[core_ids, :]\n",
        "\n",
        "        data = Data(x=core_songs, edge_index=graph_data.edge_index)\n",
        "        # Transform to sparse tensor if the transformation is given\n",
        "        data = data if self.pre_transform is None else self.pre_transform(data)\n",
        "        \n",
        "        torch.save(self.collate([data]), self.processed_paths[0])"
      ],
      "metadata": {
        "id": "fXPbCfn9L-Wy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph_dataset = MSongsDataset(root='.', transform=T.ToSparseTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpZKdJqbNGTV",
        "outputId": "3ee8ef64-c5be-44a6-80a0-16daba8ef6b7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split = RandomLinkSplit(num_val=0.15, num_test=0.15, is_undirected=True,\n",
        "                            add_negative_train_samples=False, neg_sampling_ratio=0.8, split_labels=True)\n",
        "train_data, val_data, test_data = split(graph_dataset[0])"
      ],
      "metadata": {
        "id": "b6OtwYPKVy7h"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MODELS"
      ],
      "metadata": {
        "id": "uPi4yuf0L8oN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VAE GNN"
      ],
      "metadata": {
        "id": "MW7lD6DpldqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://towardsdatascience.com/graph-neural-networks-with-pyg-on-node-classification-link-prediction-and-anomaly-detection-14aa38fe1275\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        return self.conv2(x, edge_index)\n",
        "\n",
        "    def decode(self, z, edge_label_index):\n",
        "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(\n",
        "            dim=-1\n",
        "        )  # product of a pair of nodes on each edge\n",
        "\n",
        "    def decode_all(self, z):\n",
        "        prob_adj = z @ z.t()\n",
        "        return (prob_adj > 0).nonzero(as_tuple=False).t()\n",
        "    \n",
        "\n",
        "def train_link_predictor(\n",
        "    model, train_data, val_data, optimizer, criterion, n_epochs=100\n",
        "):\n",
        "    train_losses, val_aucs = [], []\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        z = model.encode(train_data.x, train_data.edge_index)\n",
        "\n",
        "        # sampling training negatives for every training epoch\n",
        "        neg_edge_index = negative_sampling(\n",
        "            edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
        "            num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
        "\n",
        "        edge_label_index = torch.cat(\n",
        "            [train_data.edge_label_index, neg_edge_index],\n",
        "            dim=-1,\n",
        "        )\n",
        "        edge_label = torch.cat([\n",
        "            train_data.edge_label,\n",
        "            train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
        "        ], dim=0)\n",
        "\n",
        "        out = model.decode(z, edge_label_index).view(-1)\n",
        "        loss = criterion(out, edge_label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        val_auc = eval_link_predictor(model, val_data)\n",
        "        train_losses.append(loss.item())\n",
        "        val_aucs.append(val_auc)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch: {epoch:03d}, Train Loss: {loss:.3f}, Val AUC: {val_auc:.3f}\")\n",
        "\n",
        "    return model, train_losses, val_aucs\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_link_predictor(model, data):\n",
        "\n",
        "    model.eval()\n",
        "    z = model.encode(data.x, data.edge_index)\n",
        "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
        "\n",
        "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())"
      ],
      "metadata": {
        "id": "5QDA7HO4Xe3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Net(graph_dataset.num_features, 128, 64).to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Move the data to the gpu if available\n",
        "train_data = train_data.to(device)\n",
        "val_data = val_data.to(device)\n",
        "test_data = test_data.to(device)\n",
        "\n",
        "model, train_losses, val_aucs = train_link_predictor(model, train_data, val_data, optimizer, criterion)"
      ],
      "metadata": {
        "id": "OqO-IrYrX2OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_auc = eval_link_predictor(model, test_data)\n",
        "print(f\"Test: {test_auc:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjC-evdrgK8I",
        "outputId": "ae269c9a-dbfb-48b4-ec23-39b0daafcd04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test: 0.961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAGEConv"
      ],
      "metadata": {
        "id": "AMTa2eINlgrg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb = graph_dataset[0].x\n",
        "adj_t = graph_dataset[0].adj_t\n",
        "num_nodes = emb.size(0)"
      ],
      "metadata": {
        "id": "QcoT7jXLMgTg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import torch_geometric.transforms as T\n",
        "\n",
        "from torch import Tensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch_geometric.utils import negative_sampling, convert, to_dense_adj\n",
        "from torch_geometric.nn import GCNConv, SAGEConv\n",
        "from torch_geometric.nn.conv import MessagePassing"
      ],
      "metadata": {
        "id": "7ejk4jhl2i75"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SAGE(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout, aggr=\"add\"):\n",
        "        super(SAGE, self).__init__()\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(SAGEConv(in_channels, hidden_channels, normalize=True, aggr=aggr))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(SAGEConv(hidden_channels, hidden_channels, normalize=True, aggr=aggr))\n",
        "        self.convs.append(SAGEConv(hidden_channels, out_channels, normalize=True, aggr=aggr))\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs[:-1]:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.convs[-1](x, adj_t)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DotProductLinkPredictor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DotProductLinkPredictor, self).__init__()\n",
        "\n",
        "    def forward(self, x_i, x_j):\n",
        "        out = (x_i*x_j).sum(-1)\n",
        "        return torch.sigmoid(out)\n",
        "    \n",
        "    def reset_parameters(self):\n",
        "      pass"
      ],
      "metadata": {
        "id": "Wh5BXtt9AjCO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize our model and LinkPredictor\n",
        "hidden_dimension = 256\n",
        "model = SAGE(emb.size(1), hidden_dimension, hidden_dimension, 7, 0.3).to(device)\n",
        "predictor = DotProductLinkPredictor().to(device)"
      ],
      "metadata": {
        "id": "I9xQ15NcAqmE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #### Train loop\n",
        "def create_train_batch(all_pos_train_edges, perm, edge_index):\n",
        "    # First, we get our positive edges of dimensions (2, perm)     \n",
        "    pos_edges = all_pos_train_edges[:, perm].to(device)\n",
        "\n",
        "    # We then sample the negative edges using PyG functionality\n",
        "    neg_edges = negative_sampling(edge_index, num_nodes=num_nodes,\n",
        "                                  num_neg_samples=perm.shape[0], method='dense').to(device)\n",
        "\n",
        "    # Our training batch is just the positive edges concatanted with the negative ones\n",
        "    train_edge = torch.cat([pos_edges, neg_edges], dim=1)  \n",
        "\n",
        "    # Our labels are all 1 for the positive edges and 0 for the negative ones                          \n",
        "    pos_label = torch.ones(pos_edges.shape[1], )\n",
        "    neg_label = torch.zeros(neg_edges.shape[1], )\n",
        "    train_label = torch.cat([pos_label, neg_label], dim=0).to(device)\n",
        "\n",
        "    return train_edge, train_label\n",
        "  \n",
        "def train(model, predictor, x, adj_t, train_data, loss_fn, optimizer, batch_size, num_epochs, edge_model=False, spd=None):\n",
        "    # adj_t isn't used everywhere in PyG yet, so we switch back to edge_index for negative sampling\n",
        "    row, col, edge_attr = adj_t.t().coo()\n",
        "    edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "    model.train()\n",
        "    predictor.train()\n",
        "\n",
        "    model.reset_parameters()\n",
        "    predictor.reset_parameters()\n",
        "\n",
        "    all_pos_train_edges = train_data.pos_edge_label_index\n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_total_loss = 0\n",
        "        for perm in DataLoader(range(all_pos_train_edges.shape[1]), batch_size, shuffle=True):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_edge, train_label = create_train_batch(all_pos_train_edges, perm, edge_index)\n",
        "\n",
        "            # Use the GNN to generate node embeddings\n",
        "            if edge_model:\n",
        "                h = model(x, edge_index, spd)\n",
        "            else:\n",
        "                h = model(x, adj_t)\n",
        "\n",
        "            # Get predictions for our batch and compute the loss\n",
        "            preds = predictor(h[train_edge[0]], h[train_edge[1]])\n",
        "            loss = loss_fn(preds, train_label)\n",
        "\n",
        "            epoch_total_loss += loss.item()\n",
        "\n",
        "            # Update our parameters\n",
        "            loss.backward()\n",
        "            # To avoid exploding gradient problem\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "        print(f'Epoch {epoch} has loss {round(epoch_total_loss, 4)}')"
      ],
      "metadata": {
        "id": "w62Rja6n3ZSm",
        "cellView": "form"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ae-vledT3Qz",
        "outputId": "9299befc-13cf-471a-e047-b3149db76c22"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/517.2 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.0/517.2 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: in order to evaluate the predictions I should consider the similarity score that I have in the dataset, otherwise the order of prediction doesn't matter..."
      ],
      "metadata": {
        "id": "uy1JJCVZ1mRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_dict(edges, k):\n",
        "    '''\n",
        "        It returns the dictionary where for each node I have the list of connected\n",
        "        (similar) ones.\n",
        "\n",
        "        Parameters:\n",
        "            - edges: torch.tensor\n",
        "                The edges between the nodes.\n",
        "            - k: int\n",
        "                It is used to filter and keep only the songs with more than k similar\n",
        "                songs.\n",
        "        \n",
        "        Returns:\n",
        "            - dict\n",
        "                The dictionary with the songs as key and the list of similar songs\n",
        "                as values.\n",
        "    '''\n",
        "    songs = {}\n",
        "    # Iterate over the columns of the edges tensor (with dim. (2, N))\n",
        "    for i in range(edges.size(1)):\n",
        "        src = edges[0, i].item()\n",
        "        dest = edges[1, i].item()\n",
        "        # Save for each song the similar ones\n",
        "        if src not in songs:\n",
        "            songs[src] = []\n",
        "        if dest not in songs:\n",
        "            songs[dest] = []\n",
        "        # We need to save in both way since the edges are undirected\n",
        "        songs[src].append(dest)\n",
        "        songs[dest].append(src)\n",
        "\n",
        "    # Delete the songs with less than k links from the dictionary\n",
        "    songs = {song: similar for song, similar in songs.items() if len(similar) >= k}\n",
        "    if len(songs) < 200:\n",
        "        print(f\"WARNING: the function kept {len(songs)} songs.\")\n",
        "    return songs\n",
        "\n",
        "\n",
        "def compute_AP_k(predictions, target, k):\n",
        "    '''\n",
        "        It computes the average precision at k for the given lists.\n",
        "\n",
        "        Parameters:\n",
        "            - predictions: list\n",
        "                The list that contains the ids of the songs predicted as similar.\n",
        "            - target: list\n",
        "                The groundtruth list of similar songs.\n",
        "            - k: int\n",
        "                The value to compute the AP at.\n",
        "            \n",
        "        Returns:\n",
        "            - float\n",
        "                It returns the AP@k.\n",
        "    '''\n",
        "    score=count = 0\n",
        "\n",
        "    # Take the minimum value between k and the number of predicted edges\n",
        "    k = min(k, len(predictions))\n",
        "    for i in range(1, k+1):\n",
        "        if predictions[i-1] in target and predictions[i-1] not in predictions[0:(i-1)]:\n",
        "            count += 1\n",
        "            score = score + count/i \n",
        "    \n",
        "    score = score / k\n",
        "    return score\n",
        "\n",
        "\n",
        "def compute_mAP_k(songs_dict, destinations, predictions, k):\n",
        "    '''\n",
        "        It computes the mean average precision at k on a set of predictions and\n",
        "        target labels.\n",
        "\n",
        "        Parameters:\n",
        "            - songs_dict: dict\n",
        "                The dictionary with the songs as keys and the similar ones as values.\n",
        "            - destinations: torch.tensor\n",
        "                The destination nodes for which I computed the predictions [src, dest]\n",
        "                for each song.\n",
        "            - predictions: torch.tensor\n",
        "                The tensor that contains the probability to have a link between each\n",
        "                pair of nodes.\n",
        "            - k: int\n",
        "                The value to compute the mAP at.\n",
        "\n",
        "        Returns:\n",
        "            - float\n",
        "                It return the mAP@k.\n",
        "    '''\n",
        "    scores = []\n",
        "    # Iterate over the number of songs \n",
        "    for i in range(predictions.size(0)):\n",
        "        # Take the id of the song\n",
        "        song = list(songs_dict.keys())[i]\n",
        "        # Retrieve the k most probable predicted links (edges)\n",
        "        top_k_idx = torch.topk(predictions[i, :], k)[1]\n",
        "        # Take the ids of the most probable predicted nodes\n",
        "        predicted_k = destinations[i, top_k_idx]\n",
        "        \n",
        "        # The nodes similar to 'song'\n",
        "        target_nodes = songs_dict[song][:k]\n",
        "        # Compute the AP@k\n",
        "        apk = compute_AP_k(predicted_k.tolist(), target_nodes, k)\n",
        "        scores.append(apk)\n",
        "\n",
        "    return np.mean(scores)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, predictor, embeddings, adj_t, test_data, k):\n",
        "    '''\n",
        "        It test the model and it returns the mAP@k, given the model and the predictor.\n",
        "\n",
        "        Parameters:\n",
        "            - model:\n",
        "                The GNN model that creates the embeddins for the nodes.\n",
        "            - predictor:\n",
        "                The predictor that returns the probability of a link for each pair\n",
        "                of nodes.\n",
        "            - embeddings: torch.tensor\n",
        "                The embeddings of the nodes.\n",
        "            - adj_t\n",
        "    '''\n",
        "    model.eval()\n",
        "    predictor.eval()\n",
        "\n",
        "    h = model(embeddings, adj_t)\n",
        "\n",
        "    # Create the dictionary that keep songs with at least k similar ones and the indices of the similars\n",
        "    similar_songs = get_similar_dict(test_data.pos_edge_label_index, k)\n",
        "    \n",
        "    pos_eval_edge = test_data.pos_edge_label_index.to(device)\n",
        "\n",
        "    num_test_nodes = k*2\n",
        "    predictions = []\n",
        "    destinations = []\n",
        "    # TODO: repeat this operation n times and take the mean, because you will consider more random nodes\n",
        "    for song, similars in similar_songs.items():\n",
        "\n",
        "        sim_dest_nodes = torch.tensor(similars[:k])\n",
        "        # I have to choose wrong, random nodes, therefore I remove the similars from the choice\n",
        "        rand_nodes = pos_eval_edge[0, torch.isin(pos_eval_edge[0,:], sim_dest_nodes, invert=True)]\n",
        "        # The number of random nodes to take\n",
        "        rand_num = num_test_nodes - len(sim_dest_nodes)\n",
        "\n",
        "        rand_nodes = torch.tensor(np.random.choice(rand_nodes, rand_num, replace=False))\n",
        "\n",
        "        dest = torch.cat([sim_dest_nodes, rand_nodes])\n",
        "        src = torch.full((len(dest), ), song)\n",
        "\n",
        "        pred_song = predictor(h[src], h[dest]).squeeze().cpu()\n",
        "\n",
        "        destinations.append(dest)\n",
        "        predictions.append(pred_song)\n",
        "        break\n",
        "\n",
        "    predictions = torch.stack(predictions)\n",
        "    destinations = torch.stack(destinations)\n",
        "\n",
        "    map_k = compute_mAP_k(similar_songs, destinations, predictions, k)\n",
        "\n",
        "    return map_k"
      ],
      "metadata": {
        "id": "VoLmLLKZUZv0"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KFhIFicNXV2",
        "outputId": "9c93804f-91c7-4cb2-eb8b-0050614554f4"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.SAGE"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(\n",
        "            list(model.parameters())  +\n",
        "            list(predictor.parameters()), lr=0.01)\n",
        "\n",
        "train(model, predictor, emb, adj_t, train_data, torch.nn.BCELoss(), \n",
        "      optimizer, 64 * 1024, 30)"
      ],
      "metadata": {
        "id": "sdRV-uN2MwCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map = test(model, predictor, emb, adj_t, test_data, 20)"
      ],
      "metadata": {
        "id": "4BD3yMS6Wk3T"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Sl4X3PdDFny",
        "outputId": "3e07911b-941e-4395-9e14-82fa19f468ae"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.27885507509346513"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    }
  ]
}